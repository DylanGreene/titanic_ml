{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries and Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Open Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open data files and read into dataframes\n",
    "train = (pd.read_csv('train.csv')).set_index('PassengerId')\n",
    "X_score = (pd.read_csv('test.csv')).set_index('PassengerId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split training features from class\n",
    "X_train = train[list(X_score)]\n",
    "y_train = train[['Survived']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation of Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Use median imputation for age\n",
    "median_age = np.median(X_train['Age'].dropna())\n",
    "X_train = X_train.fillna({'Age': median_age})\n",
    "X_score = X_score.fillna({'Age': median_age})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Only use the letter for the cabin\n",
    "def cabin_clean(row):\n",
    "    if not pd.isnull(row['Cabin']):\n",
    "        return (row['Cabin'])[0]\n",
    "X_train.Cabin = X_train.apply(cabin_clean, axis=1)\n",
    "X_score.Cabin = X_score.apply(cabin_clean, axis=1)\n",
    "# Fill any NaNs with most common cabin letter from training set\n",
    "cabin_imp_val = X_train.Cabin.value_counts().index[0]\n",
    "X_train = X_train.fillna({'Cabin': cabin_imp_val})\n",
    "X_score = X_score.fillna({'Cabin': cabin_imp_val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill NaNs with most common categorical value\n",
    "embarked_imp_val = X_train.Embarked.value_counts().index[0]\n",
    "X_train = X_train.fillna({'Embarked': embarked_imp_val})\n",
    "X_score = X_score.fillna({'Embarked': embarked_imp_val})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Use median impuation for fare\n",
    "median_fare = np.median(X_train['Fare'].dropna())\n",
    "X_train = X_train.fillna({'Fare': median_fare})\n",
    "X_score = X_score.fillna({'Fare': median_fare})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Categorical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Features with presumably no predictive power hsould be dropped rather than encoded\n",
    "X_train = X_train.drop(['Name', 'Ticket'], axis=1)\n",
    "X_score = X_score.drop(['Name', 'Ticket'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# One-hot-encode remaining categorical features\n",
    "X_train = pd.get_dummies(X_train, columns=['Sex', 'Cabin', 'Embarked'])\n",
    "X_score = pd.get_dummies(X_score, columns=['Sex', 'Cabin', 'Embarked'])\n",
    "# Add empty column for 'Cabin_T' which was not in score\n",
    "X_score['Cabin_T'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ensure columns are ordered the same for scikit-learn\n",
    "X_score = X_score[list(X_train.columns)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Known Data for Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_split, X_test_split, y_train_split, y_test_split = train_test_split(\n",
    "    X_train, y_train, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    \n",
    "]\n",
    "\n",
    "classifier_names = [\n",
    "    '',\n",
    "    ''\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.83      0.82      0.82       134\n",
      "          1       0.73      0.74      0.74        89\n",
      "\n",
      "avg / total       0.79      0.79      0.79       223\n",
      "\n",
      "0.789237668161\n"
     ]
    }
   ],
   "source": [
    "test_pipeline = Pipeline([\n",
    "    ('grd', GradientBoostingClassifier(n_estimators=500))\n",
    "])\n",
    "test_pipeline.fit(X_train_split, y_train_split.values.ravel())\n",
    "y_pred_split = test_pipeline.predict(X_test_split)\n",
    "print(classification_report(y_test_split, y_pred_split))\n",
    "print(metrics.accuracy_score(y_test_split, y_pred_split))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Gradient Boosting Forest On Full Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the pipeline with a PCA decomp step\n",
    "pipeline = Pipeline([\n",
    "    ('pca', PCA()),\n",
    "    ('grd', GradientBoostingClassifier(n_estimators=500))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('pca', PCA(copy=True, iterated_power='auto', n_components=None, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)), ('grd', GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
       "              max_features=N...      presort='auto', random_state=None, subsample=1.0, verbose=0,\n",
       "              warm_start=False))])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the pipeline to the training set\n",
    "pipeline.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the Unknowns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_score['Survived'] = pipeline.predict(X_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_score[['Survived']].to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
